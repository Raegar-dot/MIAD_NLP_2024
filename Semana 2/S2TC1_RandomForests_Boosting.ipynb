{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/images/banner_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>  Grupo 22 </center>\n",
    "\n",
    "<center>David Alejandro Rojas Castro - da.rojasc123@uniandes.edu.co </center>\n",
    "<center>Camila Malagón Suarez - c.malagons@uniandes.edu.co</center>\n",
    "<center>Luis David Gutierrez - ld.gutierrezl1@uniandes.edu.co</center>\n",
    "<center>David Zapata Vásquez - d.zapata11@uniandes.edu.co</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller: Construcción e implementación de modelos Bagging, Random Forest y XGBoost\n",
    "\n",
    "En este taller podrán poner en práctica sus conocimientos sobre la construcción e implementación de modelos de Bagging, Random Forest y XGBoost. El taller está constituido por 8 puntos, en los cuales deberan seguir las intrucciones de cada numeral para su desarrollo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos predicción precio de automóviles\n",
    "\n",
    "En este taller se usará el conjunto de datos de Car Listings de Kaggle donde cada observación representa el precio de un automóvil teniendo en cuenta distintas variables como año, marca, modelo, entre otras. El objetivo es predecir el precio del automóvil. Para más detalles puede visitar el siguiente enlace: [datos](https://www.kaggle.com/jpayne/852k-used-car-listings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Year</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>M_Camry</th>\n",
       "      <th>M_Camry4dr</th>\n",
       "      <th>M_CamryBase</th>\n",
       "      <th>M_CamryL</th>\n",
       "      <th>M_CamryLE</th>\n",
       "      <th>M_CamrySE</th>\n",
       "      <th>M_CamryXLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21995</td>\n",
       "      <td>2014</td>\n",
       "      <td>6480</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13995</td>\n",
       "      <td>2014</td>\n",
       "      <td>39972</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>17941</td>\n",
       "      <td>2016</td>\n",
       "      <td>18989</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>12493</td>\n",
       "      <td>2014</td>\n",
       "      <td>51330</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>7994</td>\n",
       "      <td>2007</td>\n",
       "      <td>116065</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Price  Year  Mileage  M_Camry  M_Camry4dr  M_CamryBase  M_CamryL  \\\n",
       "7    21995  2014     6480        0           0            0         1   \n",
       "11   13995  2014    39972        0           0            0         0   \n",
       "167  17941  2016    18989        0           0            0         0   \n",
       "225  12493  2014    51330        0           0            0         1   \n",
       "270   7994  2007   116065        0           1            0         0   \n",
       "\n",
       "     M_CamryLE  M_CamrySE  M_CamryXLE  \n",
       "7            0          0           0  \n",
       "11           1          0           0  \n",
       "167          0          1           0  \n",
       "225          0          0           0  \n",
       "270          0          0           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importación de librerías\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "# Lectura de la información de archivo .csv\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/datasets/dataTrain_carListings.zip')\n",
    "\n",
    "# Preprocesamiento de datos para el taller\n",
    "data = data.loc[data['Model'].str.contains('Camry')].drop(['Make', 'State'], axis=1)\n",
    "data = data.join(pd.get_dummies(data['Model'], prefix='M'))\n",
    "data = data.drop(['Model'], axis=1)\n",
    "\n",
    "# Visualización dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de variables predictoras (X) y variable de interés (y)\n",
    "y = data['Price']\n",
    "X = data.drop(['Price'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de datos en set de entrenamiento y test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 1 - Árbol de decisión manual\n",
    "\n",
    "En la celda 1 creen un árbol de decisión **manualmente**  que considere los set de entrenamiento y test definidos anteriormente y presenten el RMSE y MAE del modelo en el set de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE en el conjunto de test: 1935.1155006739648\n",
      "MAE en el conjunto de test: 1458.0246928139518\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Función para calcular la media de los precios\n",
    "def mean(values):\n",
    "    return np.mean(values)\n",
    "\n",
    "# Función para calcular la varianza total\n",
    "def variance(values, split_value):\n",
    "    return np.sum((values - split_value) ** 2)\n",
    "\n",
    "# Función para evaluar posibles splits\n",
    "def test_split(index, value, dataset):\n",
    "    left, right = list(), list()\n",
    "    for row in dataset:\n",
    "        if row[index] < value:\n",
    "            left.append(row)\n",
    "        else:\n",
    "            right.append(row)\n",
    "    return left, right\n",
    "\n",
    "# Función para calcular el mejor split\n",
    "def get_split(dataset):\n",
    "    b_index, b_value, b_score, b_groups = None, None, float('inf'), None\n",
    "    for index in range(len(dataset[0])-1):\n",
    "        unique_values = set([row[index] for row in dataset])\n",
    "        for value in unique_values:\n",
    "            groups = test_split(index, value, dataset)\n",
    "            y_left = [row[-1] for row in groups[0]]\n",
    "            y_right = [row[-1] for row in groups[1]]\n",
    "            if len(y_left) == 0 or len(y_right) == 0:\n",
    "                continue  # Evita splits que no dividan los datos adecuadamente\n",
    "            p_left, p_right = mean(y_left), mean(y_right)\n",
    "            current_score = variance(y_left, p_left) + variance(y_right, p_right)\n",
    "            if current_score < b_score:\n",
    "                b_index, b_value, b_score, b_groups = index, value, current_score, groups\n",
    "    if b_groups is None and b_index is not None:  # Añadir un split por defecto si no se encuentra ninguno\n",
    "        median = np.median([row[b_index] for row in dataset])\n",
    "        b_groups = test_split(b_index, median, dataset)\n",
    "    elif b_groups is None:  # Si todos los intentos fallan\n",
    "        b_index = 0  # Uso el primer índice disponible como último recurso\n",
    "        median = np.median([row[b_index] for row in dataset])\n",
    "        b_groups = test_split(b_index, median, dataset)\n",
    "    return {'index': b_index, 'value': b_value, 'groups': b_groups}\n",
    "\n",
    "# Función para crear una hoja terminal\n",
    "def to_terminal(group):\n",
    "    outcomes = [row[-1] for row in group]\n",
    "    return mean(outcomes)\n",
    "\n",
    "# Función para crear divisiones de nodos hijos o hacer terminales\n",
    "def split(node, max_depth, depth):\n",
    "    if 'groups' not in node or node['groups'] is None:\n",
    "        node['left'] = node['right'] = to_terminal([row[-1] for row in dataset])\n",
    "        return\n",
    "    left, right = node['groups']\n",
    "    del(node['groups'])\n",
    "    if not left or not right:\n",
    "        node['left'] = node['right'] = to_terminal(left + right)\n",
    "        return\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "    node['left'] = get_split(left)\n",
    "    split(node['left'], max_depth, depth+1)\n",
    "    node['right'] = get_split(right)\n",
    "    split(node['right'], max_depth, depth+1)\n",
    "\n",
    "# Función para construir un árbol\n",
    "def build_tree(train, max_depth):\n",
    "    root = get_split(train)\n",
    "    split(root, max_depth, 1)\n",
    "    return root\n",
    "\n",
    "# Función para hacer una predicción con el árbol\n",
    "def predict(node, row):\n",
    "    if row[node['index']] < node['value']:\n",
    "        if isinstance(node['left'], dict):\n",
    "            return predict(node['left'], row)\n",
    "        else:\n",
    "            return node['left']\n",
    "    else:\n",
    "        if isinstance(node['right'], dict):\n",
    "            return predict(node['right'], row)\n",
    "        else:\n",
    "            return node['right']\n",
    "\n",
    "# Convertir datos a una lista de listas\n",
    "dataset = np.column_stack((X_train, y_train)).tolist()\n",
    "\n",
    "# Construir el árbol\n",
    "tree = build_tree(dataset, max_depth=3)\n",
    "\n",
    "# Función para calcular RMSE\n",
    "def rmse_metric(actual, predicted):\n",
    "    sum_error = 0.0\n",
    "    for i in range(len(actual)):\n",
    "        prediction_error = predicted[i] - actual[i]\n",
    "        sum_error += (prediction_error ** 2)\n",
    "    mean_error = sum_error / float(len(actual))\n",
    "    return np.sqrt(mean_error)\n",
    "\n",
    "# Hacer predicciones en el conjunto de test\n",
    "predictions = [predict(tree, row.tolist()) for row in X_test.values]\n",
    "actual = y_test.tolist()\n",
    "\n",
    "# Calcular RMSE y MAE\n",
    "rmse = rmse_metric(actual, predictions)\n",
    "mae = np.mean(np.abs(np.array(actual) - np.array(predictions)))\n",
    "\n",
    "print(\"RMSE en el conjunto de test:\", rmse)\n",
    "print(\"MAE en el conjunto de test:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análisis de resultados:**\n",
    "RMSE (Root Mean Square Error): 1935.12\n",
    "MAE (Mean Absolute Error): 1458.02\n",
    "\n",
    "**Conclusión del Análisis:**\n",
    "El modelo de árbol de decisión manual alcanzó un **RMSE de 1935.12** y un **MAE de 1458.02** en el conjunto de test. Estos valores proporcionan una medida de cuánto se desvían las predicciones del modelo de los valores reales. En este contexto, un RMSE de 1935.12 indica que, en promedio, las predicciones del modelo pueden estar dentro de un rango de aproximadamente 1935 unidades monetarias del precio real del automóvil. Similarmente, el MAE de 1458.02 sugiere que, en promedio, los errores absolutos de las predicciones están alrededor de 1458 unidades.\n",
    "\n",
    "**Interpretación:**\n",
    "* **Magnitud de los errores:** Los valores de RMSE y MAE son relativamente altos, lo que podría indicar que el modelo, aunque funcional, no captura completamente la complejidad o las relaciones subyacentes en los datos. Esto es común en modelos de árboles de decisión simples sin refinamiento o ajuste de parámetros, especialmente cuando se construyen manualmente sin optimizaciones avanzadas.\n",
    "* **Impacto de los errores grandes:** El RMSE mayor que el MAE sugiere que hay varios errores grandes que afectan más significativamente al RMSE debido a su naturaleza de penalización cuadrática. Esto podría ser indicativo de sobreajuste en ciertas partes del árbol o de la incapacidad del modelo para manejar adecuadamente las variaciones extremas en los datos.\n",
    "\n",
    "**Implicaciones:**\n",
    "Este modelo podría servir como un punto de partida básico, pero claramente hay espacio para mejoras. El desempeño actual puede no ser suficiente para aplicaciones prácticas donde se requieren predicciones precisas de precios de automóviles, como en sistemas de recomendación para compradores de autos o en aplicaciones de inventario para vendedores de autos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 2 - Bagging manual\n",
    "\n",
    "En la celda 2 creen un modelo bagging **manualmente** con 10 árboles de regresión y comenten sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE en el conjunto de test: 1816.738261051669\n",
      "MAE en el conjunto de test: 1353.8057201768336\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def bootstrap_sample(data):\n",
    "    n_samples = len(data)\n",
    "    indices = np.random.choice(n_samples, size=n_samples, replace=True)\n",
    "    return data[indices]\n",
    "\n",
    "def bagging_predict(trees, row):\n",
    "    predictions = [predict(tree, row) for tree in trees]\n",
    "    return np.mean(predictions)  # Para regresión\n",
    "\n",
    "# Crear múltiples árboles de decisión\n",
    "n_trees = 10\n",
    "trees = []\n",
    "\n",
    "for _ in range(n_trees):\n",
    "    sample = bootstrap_sample(np.array(dataset))\n",
    "    tree = build_tree(sample.tolist(), max_depth=3)\n",
    "    trees.append(tree)\n",
    "\n",
    "# Evaluar el ensamble en el conjunto de test\n",
    "predictions = [bagging_predict(trees, row.tolist()) for row in X_test.values]\n",
    "actual = y_test.tolist()\n",
    "\n",
    "# Calcular RMSE y MAE\n",
    "rmse = rmse_metric(actual, predictions)\n",
    "mae = np.mean(np.abs(np.array(actual) - np.array(predictions)))\n",
    "\n",
    "print(\"RMSE en el conjunto de test:\", rmse)\n",
    "print(\"MAE en el conjunto de test:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análisis de resultados:**\n",
    "\n",
    "Bagging Manual:\n",
    "\n",
    "RMSE: 1816.74\n",
    "\n",
    "MAE: 1353.81\n",
    "\n",
    "**Observaciones:**\n",
    "* **Reducción de Error:** El modelo de bagging ha reducido tanto el RMSE como el MAE en comparación con un único árbol de decisión. El RMSE se ha reducido en aproximadamente 118.38 unidades y el MAE en aproximadamente 104.22 unidades.\n",
    "\n",
    "**Interpretación del RMSE y MAE:**\n",
    "* **RMSE (Root Mean Square Error):** Este mide la magnitud de los errores entre los valores predichos y los valores reales. Dado que el RMSE penaliza más los errores grandes (por el cuadrado de las diferencias), una reducción en el RMSE sugiere una mejora en la precisión del modelo, especialmente en la reducción de grandes errores de predicción.\n",
    "* **MAE (Mean Absolute Error):** Este mide el error promedio en las predicciones; es menos sensible a los valores atípicos que el RMSE. La reducción del MAE indica que, en promedio, las predicciones del modelo de bagging están más cerca de los valores reales.\n",
    "\n",
    "**Conclusiones:**\n",
    "* **Efectividad del Bagging:** La mejora en ambos, RMSE y MAE, para el modelo de bagging indica que este método puede ser más efectivo para este conjunto de datos específico. El bagging ha ayudado probablemente a reducir la varianza del modelo, haciéndolo más robusto contra el sobreajuste y mejorando la precisión general en los datos de prueba.\n",
    "* **Sobreajuste:** Dado que el bagging utiliza múltiples modelos (árboles en este caso) entrenados en diferentes subconjuntos del dataset, es menos probable que el modelo resultante se sobreajuste a los datos de entrenamiento en comparación con un solo árbol de decisión. Esto podría explicar la mejora en la precisión observada con el modelo de bagging.\n",
    "* **Recomendaciones:** Para este conjunto de datos y problema específico (predicción del precio de automóviles), el uso de bagging presenta una clara ventaja sobre el uso de un solo árbol de decisión. Podría ser beneficioso explorar aún más los métodos de ensamblaje, quizás aumentando el número de árboles en el bagging o utilizando otras técnicas de ensamblaje como Random Forest o Boosting para comparar rendimientos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 3 - Bagging con librería\n",
    "\n",
    "En la celda 3, con la librería sklearn, entrenen un modelo bagging con 10 árboles de regresión y el parámetro `max_features` igual a `log(n_features)` y comenten sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 4 - Random forest con librería\n",
    "\n",
    "En la celda 4, usando la librería sklearn entrenen un modelo de Randon Forest para regresión  y comenten sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 5 - Calibración de parámetros Random forest\n",
    "\n",
    "En la celda 5, calibren los parámetros max_depth, max_features y n_estimators del modelo de Randon Forest para regresión, comenten sobre el desempeño del modelo y describan cómo cada parámetro afecta el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 6 - XGBoost con librería\n",
    "\n",
    "En la celda 6 implementen un modelo XGBoost de regresión con la librería sklearn y comenten sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 7 - Calibración de parámetros XGBoost\n",
    "\n",
    "En la celda 7 calibren los parámetros learning rate, gamma y colsample_bytree del modelo XGBoost para regresión, comenten sobre el desempeño del modelo y describan cómo cada parámetro afecta el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 8 - Comparación y análisis de resultados\n",
    "En la celda 8 comparen los resultados obtenidos de los diferentes modelos (random forest y XGBoost) y comenten las ventajas del mejor modelo y las desventajas del modelo con el menor desempeño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 8\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
